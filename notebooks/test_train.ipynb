{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the project root directory (parent of the notebooks folder)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Add the src folder to the Python path\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_preprocessing import DataLoaders\n",
    "\n",
    "loaders = DataLoaders(trial_data=False)\n",
    "train_dataloader = loaders.get_train_dataloader()\n",
    "test_dataloader = loaders.get_test_dataloader()\n",
    "# for images, labels in train_dataloader:\n",
    "#     print(f'Batch of images shape: {images.shape}')\n",
    "#     print(f'Batch of labels: {labels}')\n",
    "\n",
    "# for images, labels in test_dataloader:\n",
    "#     print(f'Batch of images shape: {images.shape}')\n",
    "#     print(f'Batch of labels: {labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtiny_vit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tiny_vit_5m_224\n\u001b[1;32m      8\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      9\u001b[0m learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "\n",
    "from vit_pytorch import SimpleViT\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import wandb\n",
    "from src.models.tiny_vit import tiny_vit_5m_224\n",
    "\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "with open('../data/country_to_index_mapped.json', 'r') as f:\n",
    "    num_classes = len(json.load(f))\n",
    "\n",
    "model = tiny_vit_5m_224(pretrained=True)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "device = torch.device(\"mps\")\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")\n",
    "# Assuming parameters are of type float32 (4 bytes)\n",
    "param_size_in_bytes = total_params * 4\n",
    "# Convert to megabytes\n",
    "param_size_in_mb = param_size_in_bytes / (1024 ** 2)\n",
    "print(f\"Model size: {param_size_in_mb:.2f} MB\")\n",
    "\n",
    "wandb.init(\n",
    "    project=\"geoguessr AI\",\n",
    "    config={\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"architecture\": \"TinyViT-5M-224\",\n",
    "    \"dataset\": \"street-location-images- data-mapped\",\n",
    "    \"epochs\": num_epochs,\n",
    "    \"model_parameters\": total_params,\n",
    "    \"model_size\": param_size_in_mb\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(tqdm(train_dataloader)):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_dataloader)\n",
    "    train_accuracy = 100.0 * correct_predictions / total_samples\n",
    "    test_loss, test_accuracy = evaluate(model, test_dataloader, criterion, device)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "          f'Train Loss: {train_loss:.4f}, '\n",
    "          f'Train Accuracy: {train_accuracy:.2f}%, '\n",
    "          f'Test Loss: {test_loss:.4f}, '\n",
    "          f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "    wandb.log({\"train_loss\": train_loss, \"test_loss\": test_loss, \"train_accuracy\": train_accuracy, \"test_accuracy\": test_accuracy})\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "from transformers import ViTConfig\n",
    "from huggingface_hub import login, Repository\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "model_save_path = \"../data/models/\"\n",
    "repo = Repository(local_dir=model_save_path, clone_from=\"mwitjez/geoguessr_tiny_ViT\")\n",
    "\n",
    "torch.save(model, f\"{model_save_path}/geoguessr_model.bin\")\n",
    "\n",
    "config = ViTConfig()\n",
    "config.save_pretrained(model_save_path)\n",
    "\n",
    "repo.push_to_hub()\n",
    "if os.path.exists(model_save_path):\n",
    "    shutil.rmtree(model_save_path)\n",
    "    print(f\"'{model_save_path}' has been removed successfully.\")\n",
    "else:\n",
    "    print(f\"'{model_save_path}' does not exist.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
