{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the project root directory (parent of the notebooks folder)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Add the src folder to the Python path\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_preprocessing import DataLoaders\n",
    "\n",
    "loaders = DataLoaders(trial_data=True)\n",
    "train_dataloader = loaders.get_train_dataloader()\n",
    "test_dataloader = loaders.get_test_dataloader()\n",
    "# for images, labels in train_dataloader:\n",
    "#     print(f'Batch of images shape: {images.shape}')\n",
    "#     print(f'Batch of labels: {labels}')\n",
    "\n",
    "# for images, labels in test_dataloader:\n",
    "#     print(f'Batch of images shape: {images.shape}')\n",
    "#     print(f'Batch of labels: {labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mateuszwitka-jezewski/Documents/Projekty/geoguessrai/src/models/tiny_vit.py:640: UserWarning: Overwriting tiny_vit_5m_224 in registry with src.models.tiny_vit.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "/Users/mateuszwitka-jezewski/Documents/Projekty/geoguessrai/src/models/tiny_vit.py:653: UserWarning: Overwriting tiny_vit_11m_224 in registry with src.models.tiny_vit.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "/Users/mateuszwitka-jezewski/Documents/Projekty/geoguessrai/src/models/tiny_vit.py:666: UserWarning: Overwriting tiny_vit_21m_224 in registry with src.models.tiny_vit.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "/Users/mateuszwitka-jezewski/Documents/Projekty/geoguessrai/src/models/tiny_vit.py:679: UserWarning: Overwriting tiny_vit_21m_384 in registry with src.models.tiny_vit.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "/Users/mateuszwitka-jezewski/Documents/Projekty/geoguessrai/src/models/tiny_vit.py:693: UserWarning: Overwriting tiny_vit_21m_512 in registry with src.models.tiny_vit.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 20\u001b[0m\n\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m tiny_vit_5m_224(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m---> 20\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-8\u001b[39m)\n\u001b[1;32m     22\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mCosineAnnealingLR(optimizer, T_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, eta_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import json\n",
    "import wandb\n",
    "from torchmetrics import Accuracy, F1Score\n",
    "from src.models.tiny_vit import tiny_vit_5m_224\n",
    "\n",
    "num_epochs = 10\n",
    "learning_rate = 2.5e-4\n",
    "with open('../data/country_to_index_mapped.json', 'r') as f:\n",
    "    num_classes = len(json.load(f))\n",
    "\n",
    "model = tiny_vit_5m_224(pretrained=True)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=1e-5)\n",
    "f1_metric = F1Score(task='multiclass', num_classes=num_classes).to(device)\n",
    "accuracy_metric = Accuracy(task='multiclass', num_classes=num_classes).to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")\n",
    "# Assuming parameters are of type float32 (4 bytes)\n",
    "param_size_in_bytes = total_params * 4\n",
    "# Convert to megabytes\n",
    "param_size_in_mb = param_size_in_bytes / (1024 ** 2)\n",
    "print(f\"Model size: {param_size_in_mb:.2f} MB\")\n",
    "\n",
    "wandb.init(\n",
    "    project=\"geoguessr AI\",\n",
    "    config={\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"architecture\": \"TinyViT-5M-224\",\n",
    "    \"dataset\": \"street-location-images- data-mapped\",\n",
    "    \"epochs\": num_epochs,\n",
    "    \"model_parameters\": total_params,\n",
    "    \"model_size\": param_size_in_mb\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmetrics import Accuracy, F1Score\n",
    "\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "\n",
    "    accuracy_metric = Accuracy(task='multiclass', num_classes=num_classes).to(device)\n",
    "    f1_metric = F1Score(task='multiclass', num_classes=num_classes).to(device)  # For multiclass classification\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            accuracy_metric.update(predicted, labels)\n",
    "            f1_metric.update(predicted, labels)\n",
    "\n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    accuracy = accuracy_metric.compute().item() * 100  # Convert to percentage\n",
    "    f1_score = f1_metric.compute().item()  # Final F1 score\n",
    "\n",
    "    return avg_loss, accuracy, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:25<00:00, 25.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 8.3600, Train Accuracy: 0.00%, Test Loss: 8.3828, Test Accuracy: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Train Loss: 5.8863, Train Accuracy: 0.00%, Test Loss: 8.1654, Test Accuracy: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Train Loss: 4.0128, Train Accuracy: 31.11%, Test Loss: 8.0030, Test Accuracy: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Train Loss: 2.4227, Train Accuracy: 62.22%, Test Loss: 7.8515, Test Accuracy: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Train Loss: 1.3345, Train Accuracy: 86.67%, Test Loss: 7.6559, Test Accuracy: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Train Loss: 0.7041, Train Accuracy: 95.56%, Test Loss: 7.3990, Test Accuracy: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Train Loss: 0.3275, Train Accuracy: 100.00%, Test Loss: 7.1706, Test Accuracy: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Train Loss: 0.1331, Train Accuracy: 100.00%, Test Loss: 7.0221, Test Accuracy: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Train Loss: 0.0554, Train Accuracy: 100.00%, Test Loss: 6.9577, Test Accuracy: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Train Loss: 0.0288, Train Accuracy: 100.00%, Test Loss: 6.9327, Test Accuracy: 0.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9fcaec7261f4e54a364f841672ab031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.017 MB uploaded\\r'), FloatProgress(value=0.05716863054631561, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_loss</td><td>█▇▆▅▄▃▂▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▃▅▇█████</td></tr><tr><td>train_loss</td><td>█▆▄▃▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.0</td></tr><tr><td>test_loss</td><td>6.93268</td></tr><tr><td>train_accuracy</td><td>100.0</td></tr><tr><td>train_loss</td><td>0.02881</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">super-bush-7</strong> at: <a href='https://wandb.ai/m-w-jezewski/geoguessr%20AI/runs/zuzwgu13' target=\"_blank\">https://wandb.ai/m-w-jezewski/geoguessr%20AI/runs/zuzwgu13</a><br/> View project at: <a href='https://wandb.ai/m-w-jezewski/geoguessr%20AI' target=\"_blank\">https://wandb.ai/m-w-jezewski/geoguessr%20AI</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240910_182226-zuzwgu13/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(tqdm(train_dataloader)):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Update metrics (both accuracy and F1 score)\n",
    "        accuracy_metric.update(predicted, labels)\n",
    "        f1_metric.update(predicted, labels)\n",
    "\n",
    "    # Compute average loss for training\n",
    "    train_loss = running_loss / len(train_dataloader)\n",
    "    train_accuracy = accuracy_metric.compute().item() * 100  # Convert to percentage\n",
    "    train_f1_score = f1_metric.compute().item()  # F1 score\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    test_loss, test_accuracy, test_f1_score = evaluate(model, test_dataloader, criterion, device)\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "          f'Train Loss: {train_loss:.4f}, '\n",
    "          f'Train Accuracy: {train_accuracy:.2f}%, '\n",
    "          f'Train F1 Score: {train_f1_score:.4f}, '\n",
    "          f'Test Loss: {test_loss:.4f}, '\n",
    "          f'Test Accuracy: {test_accuracy:.2f}%, '\n",
    "          f'Test F1 Score: {test_f1_score:.4f}')\n",
    "\n",
    "    wandb.log({\"train_loss\": train_loss, \"test_loss\": test_loss, \"train_accuracy\": train_accuracy, \"test_accuracy\": test_accuracy, \"train_f1_score\": train_f1_score, \"test_f1_score\": test_f1_score, \"epoch\": epoch})\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "from transformers import ViTConfig\n",
    "from huggingface_hub import login, Repository\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "model_save_path = \"../data/models/\"\n",
    "repo = Repository(local_dir=model_save_path, clone_from=\"mwitjez/geoguessr_tiny_ViT\")\n",
    "\n",
    "torch.save(model, f\"{model_save_path}/geoguessr_model.bin\")\n",
    "\n",
    "config = ViTConfig()\n",
    "config.save_pretrained(model_save_path)\n",
    "\n",
    "repo.push_to_hub()\n",
    "if os.path.exists(model_save_path):\n",
    "    shutil.rmtree(model_save_path)\n",
    "    print(f\"'{model_save_path}' has been removed successfully.\")\n",
    "else:\n",
    "    print(f\"'{model_save_path}' does not exist.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
